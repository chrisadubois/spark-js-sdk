import bowser from 'bowser';

import {
  STATS,
  MQA_STATS
} from '../constants';


/**
 * @description MQAProcessor handles interval data for MQA
 * @export
 * @class MQAProcessor
 */
class MQAProcessor {
  /**
     * @constructor
     * @public
     * @memberof Meetings
     */
  constructor() {
    this.data = {
      videoReceive: [],
      audioTransmit: [],
      audioReceive: [],
      videoTransmit: []
    };
    this.intervalNumber = 1;
  }

  /**
   * @param {String} id
   * @param {Array} interval - a slice of metrics history
   * @returns {undefined}
   */
  process(id, interval) {
    let rtcCandidatePair, rtcOutVideo, rtpOutVideo, rtcInVideo, rtpInVideo, rtcOutAudio, rtcInAudio, rtpInAudio, rtpOutAudio; // TODO:
    let vsTransmit;

    const {
      videoReceive, audioTransmit, audioReceive, videoTransmit
    } = this.data;

    const sumValue = interval[0]; // the head is the last interval value, webRTC spec has some values automatically summed

    if (sumValue) {
      rtcCandidatePair = sumValue.rtcCandidatePair;
    }

    switch (id) {
      case STATS.audioSenderId:
        audioTransmit.push();
        break;
      case STATS.audioReceiverId:
        audioReceive.push();
        break;
      case STATS.videoSenderId:
        videoTransmit.push();
        break;
      case STATS.videoReceiverId:
        videoReceive.push();
        break;
      case STATS.shareSenderId:
        if (sumValue) {
          rtcOutVideo = sumValue.rtcOutVideo;
          rtpOutVideo = sumValue.rtpOutVideo;
        }
        vsTransmit = {...MQA_STATS.DEFAULT_SHARE_SENDER_STATS};
        if (bowser.name.toLowerCase() === 'firefox') {
          vsTransmit.common.remoteLossRate = rtpOutVideo ? rtpOutVideo.pliCount / (interval.length * this.intervalNumber) : -1;
          vsTransmit.common.rtpPackets = rtpOutVideo ? rtpOutVideo.packetsSent / (interval.length * this.intervalNumber) : -1;
          vsTransmit.streams[0].common.transmittedFrameRate = rtcOutVideo ? rtcOutVideo.framesEncoded / (interval.length * this.intervalNumber) : -1;
          vsTransmit.streams[0].common.rtpPackets = rtpOutVideo ? rtpOutVideo.packetsSent / (interval.length * this.intervalNumber) : -1;
        }
        else {
          vsTransmit.common.availableBitRate = rtcCandidatePair ? rtcCandidatePair.availableOutgoingBitrate : -1;
          vsTransmit.common.remoteLossRate = rtpOutVideo ? rtpOutVideo.pliCount / (interval.length * this.intervalNumber) : -1;
          vsTransmit.common.roundTripTime = rtcCandidatePair ? rtcCandidatePair.totalRoundTripTime / (interval.length * this.intervalNumber) : -1;
          vsTransmit.common.rtpPackets = rtpOutVideo ? rtpOutVideo.packetsSent / (interval.length * this.intervalNumber) : -1;
          vsTransmit.streams[0].common.rtpPackets = rtpOutVideo ? rtpOutVideo.packetsSent / (interval.length * this.intervalNumber) : -1;
          vsTransmit.streams[0].common.transmittedBitrate = rtcCandidatePair ? rtcCandidatePair.availableOutgoingBitrate : -1;
          vsTransmit.streams[0].common.transmittedFrameRate = rtcOutVideo ? rtcOutVideo.framesSent / (interval.length * this.intervalNumber) : -1;
          vsTransmit.streams[0].transmittedHeight = rtcOutVideo ? rtcOutVideo.frameHeight : -1;
          vsTransmit.streams[0].transmittedKeyFrames = rtcOutVideo ? rtcOutVideo.hugeFramesSent : -1;
          vsTransmit.streams[0].transmittedWidth = rtcOutVideo ? rtcOutVideo.frameWidth : -1;
        }
        videoTransmit.push(vsTransmit);
        break;
      default:
        break;
    }
    this.data.intervalMetadata = this.data.intervalMetadata || {...MQA_STATS.intervalMetadata};
  }

  getData() {
    this.intervalNumber += 1;

    const payload = {...this.data, intervalNumber: this.intervalNumber};

    this.data = {
      videoReceive: [],
      audioTransmit: [],
      audioReceive: [],
      videoTransmit: []
    };

    return payload;
  }
}

export default MQAProcessor;
